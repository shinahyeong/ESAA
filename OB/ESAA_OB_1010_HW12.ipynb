{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CH 09. 추천 시스템"
      ],
      "metadata": {
        "id": "R3fWoJygUYhp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##01. 추천 시스템의 개요와 배경\n"
      ],
      "metadata": {
        "id": "QXg2m611Udy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###추천 시스템의 개요\n",
        "- 추천 시스템: 사용자의 취향을 이해하고 맞춤 상품과 콘텐츠를 제공하여 자신의 사이트에 고객이 머무르는 시간을 오래 소요하게 하는 것\n",
        "- 추천 시스템의 장점\n",
        "  - 매출을 큰 폭으로 올릴 수 있음\n",
        "  - 사용자의 쇼핑 즐거움이 배가됨\n",
        "- 추천 시스템의 핵심: 사용자 자신도 좋아하는지 몰랐던 취향을 시스템이 발견하고 그에 맞는 콘텐츠를 추천해주는 것\n",
        "  - 사용자로부터 강한 신뢰를 얻고, 더 많은 추천 콘텐츠를 선택하게끔 함\n",
        "    - 많은 데이터를 얻고, 이로인해 추천 시스템은 한층 높은 정확도를 얻게 됨\n",
        "    "
      ],
      "metadata": {
        "id": "6AC_mxZHUgN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###온라인 스토어의 필수 요소, 추천 시스템\n",
        "- 추천 시스템은 특히 온라인에서 그 진가를 발휘함\n",
        " - 추천 엔진은 사용자가 무엇을 원하는지 빠르게 찾아내는 장점이 있어 사용자의 온라인 쇼핑 이용 즐거움을 배가 시킴\n",
        " - 즉, 추천 시스템으로 **사용자의 선택 부담을 해결**하는 것이 중요함\n",
        "- 온라인 스토어 -> 많은 양의 고객, 상품 관련 데이터를 보유\n",
        "  - 데이터를 이용한 추천 시스템 구성 예시\n",
        "    - 사용자가 어떤 상품을 구매했는가?\n",
        "    - 사용자가 어떤 상품을 둘러보거나 장바구니에 넣었는가?\n",
        "    - 사용자가 평가한 영화 평점은? 제품 평가는?\n",
        "    - 사용자가 스스로 작성한 자신의 취향은?\n",
        "    - 사용자가 무엇을 클릭했는가?\n",
        "  - 이렇듯 데이터를 수집하여 추천 엔진으로 부터 사용자 본인만을 위한 최신 상품, 동일한 상품을 좋아하는 다른 사람들이 좋아하는 상품 등의 추천을 진행"
      ],
      "metadata": {
        "id": "WyfL_Vm2Uj0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###추천 시스템의 유형\n",
        "- 추천 시스템의 2가지 유형\n",
        "  - 콘텐츠 기반 필터링(Content based filtering)\n",
        "  - 협업 필터링(Collavorative Filtering)\n",
        "    - 최근접 이웃 협업 필터링(Nearest Neighbor)\n",
        "    - 잠재 요인 협업 필터링(Latent Factor) -> 이게 최근의 유행 방식"
      ],
      "metadata": {
        "id": "cwnEX6W3Um6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##02. 콘텐츠 기반 필터링 추천 시스템\n",
        "- 콘텐츠 기반 필터링 방식: 특정 아이템을 매우 선호하는 경우, 그 아이템과 비슷한 콘텐츠를 가진 다른 아이템을 추천하는 방식\n",
        "  - 예시: 어떤 사용자가 좋아하는 영화 -> 해당 영화의 장르, 출연 배우, 감독, 영화 키워드 등의 **콘텐츠와 유사한 다른 영화를 추천**하는 방식\n",
        "  - 이와 같이 **사용자 선호 프로파일**을 뽑아 이와 유사한 상품을 추천해주는 방식이라고 생각하면 됨\n",
        "  "
      ],
      "metadata": {
        "id": "ivQVU-mxUqDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##03. 초근접 이웃 협업 필터링\n",
        "- 협업 필터링 방식\n",
        "  - 친구들에게 물어보는 것과 유사한 방식으로, 사용자가 아이템에 매긴 평점 정보나 상품 구매 이력과 같은 사용자 행동 양식만을 기반으로 추천을 수행하는 방식\n",
        "- 협업 필터링의 주요 목표\n",
        "- 사용자-아이템 평점 매트릭스와 같은 **축적된 사용자 행동 데이터를 기반으로 한 사용자가 아직 평가하지 않은 아이템을 예측 평가**하는 것\n",
        "\n",
        "  (즉, 예측 평가 방식이라고 생각하면 됨!)\n",
        "- 헙업 필터링 기반의 추천 시스템의 2가지 방식\n",
        "  - 최근접 이웃 방식, 잠재 요인 방식으로 나뉨\n",
        "  - 공통점: **사용자-아이템 평점 행렬 데이터**에만 의지하여 추천을 수행함\n",
        "    - 행: 개별 사용자\n",
        "    - 열: 개별 아이템\n",
        "    - 각 행과 열 위치에 해당하는 값이 평점을 나타내는 형태로 이루어짐\n",
        "    - 대다수는 많은 아이템을 열로 가지는 다차원 행렬 형태로 이뤄지고, 사용자가 아이템에 대한 평점을 매기는 경우가 많지 않기 때문에 **희소 행렬**의 특성을 가짐\n",
        "- 최근접 이웃 협업 필터링\n",
        "  - 메모리 협업 피터링이라고도 불림\n",
        "  - 사용자 기반과 아이템 기반으로 다시 나뉨\n",
        "    - 사용자 기반: 당신과 비슷한 고객들이 다음 상품도 구매했다는 취향이 비슷한 사람의 이력을 추천함\n",
        "      - 특정 사용자와 유사한 다른 사용자를 Top-N 으로 선정하여 이 Top-N 사용자가 좋아하는 아이템을 추천하는 방식\n",
        "      - 즉, 특정 사용자와 타 사용자 간의 유사도를 측정한 후 가장 유사도가 높은 Top-N의 사용자를 추출하여 그들이 선호하는 아이템을 추천함\n",
        "    - 아이템 기반: 이 상품을 선택한 다른 고객들은 다음 상품도 구매했다는 상품을 구매한 사람들의 이력을 추천함\n",
        "      - 아이템이 가지는 속성과는 상관없이 사용자들이 그 아이템을 좋아하는지, 실헝하는 지의 평가 척도가 유사한 아이템을 추천하는 기준이 되는 알고리즘\n",
        "      - 행이 개별 아이템이고 열이 개별 사용자로 행렬을 그림\n",
        "- 일반적으로 사용자 기반보다는 이이템 기반 협엽 필터링의 정확도가 더 높음\n",
        "  - 간단하게 말하면 비슷한 영화를 좋아한다고 해서 사람들의 취향이 비슷하다고 말하기엔 성급한 일반화가 될 수 있기 때문\n",
        "    - 유명한 영화는 유명해서 많은 사람들이 대부분 관람하는 경우가 다수이고, 사용자들이 평점을 매긴 상품의 개수는 많지 않은 경우가 대다수이기 때문에 다른 사람과의 유사도를 비교하기엔 어려운 경우가 많기 때문\n",
        "- 추천 시스템에서 사용되는 데이처는 피처 벡터화된 텍스트 데이터와 동일하게 다차원 희소 행렬이라는 특징이 존재 -> 코사인 유사도를 주로 이용\n",
        "\n"
      ],
      "metadata": {
        "id": "h3WK8YixUtLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##04. 잠재요인 협업 필터링"
      ],
      "metadata": {
        "id": "4QvutGRYUyGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###잠재 요인 협업 필터링의 이해\n",
        "- 잠재 요인 협업 필터링: 사용자-아이템 평점 매트릭스 속에 숨어 있는 잠재 요인을 추출하여 추천 예측을 할 수 있게 하는 기법\n",
        "  - 대규모 다차원 행렬을 SVD와 같은 차원 감소 기법으로 분해하는 과정에서 잠재요인을 추출함 -> 이를 '행렬 분해'라고 함\n",
        "  - 행렬 분해 기반 잠재 요인 협업 필터링은 넷플릭스 경연 대회에서 사용되면서 유명해짐\n",
        "  - 잠재 요인 협업 필터링의 과정  \n",
        "    - 원본 행렬에서 매트릭스 분해를 통해 **사용자-잠재요인 행렬** 하나와, **잠재요인-아이템 행렬** 하나 이렇게 2개의 행렬로 분리\n",
        "    - 이후, 이를 내적 곱을 통해 하나의 행렬로 결합 -> 사용자가 예측하지 않은 아이템에 대한 평점을 도출하게 되는 방식\n",
        "  - 잠재 요인의 가정\n",
        "    - 영화 평점 기반으로 생각해보면, 이 잠재요인은 영화가 가지는 장르별 특성 선호도로 가정할 수 있음\n",
        "      - 사용자-잠재요인 행렬: 사용자의 영화 장르에 대한 선호도\n",
        "      - 아이템-잠재요인 행렬: 영화의 장르별 특성값\n",
        "      - 이들을 내적하여 하나의 값으로 나타냄\n",
        "        -> 이 값에서 이전 원본 칼럼에 없던 값이 즉 **예측값**이 되는 방식!"
      ],
      "metadata": {
        "id": "bFHuEUPXU0Ni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 행렬 분해의 이해\n",
        "- 행렬 분해: 다차원의 매트릭스를 저차원 매트릭스로 분해하는 기법\n",
        "  - 대표적으로 SVD, NMF 등이 있음\n",
        "- 예시\n",
        "  - 평점 행렬 R이 M개의 사용자 행과 N개의 아이템행을 가진 M*N 차원으로 구성되어 있다고 가정\n",
        "    - 행렬 분해를 통해 사용자 K차원 잠재요인 행렬 P(M * K차원)과  K차원 잠재요인 아이템 행렬 QT(K * N차원)로 분해됨\n",
        "    - 이에 대한 예측 평점은 행렬 분해를 통해 얻어진 P 행렬과 QT 행렬의 내적을 통해 얻어짐\n",
        "- 행렬 분해는 보통은 SVD 방식을 이용하나, SVD는 결측값이 없는 행렬에만 적용할 수 있음\n",
        "  - 이러한 단점을 보완하기 위해 일반적인 SVD 방식이 아닌 확률적 경사 하강법이나 ALS방식을 이용하여 SVD를 수행함"
      ],
      "metadata": {
        "id": "bCe5_jP1Ubxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###확률적 경사 하강법을 이용한 행렬 분해\n",
        "- 확률적 경사하강법을 이용한 행렬 분해\n",
        "  - P와 Q를 임의의 값을 가진 행렬로 설정\n",
        "  - P와 QT값을 곱해 예측 R 행렬을 계산한 뒤, 예측 R 행렬과 실제 R 행렬에 해당하는 오류값을 계산함\n",
        "  - 이 오류 값을 최소화 하기 위해 **P와 Q행렬을 적절한 값으로 업데이트**\n",
        "  - 만족할 만한 오류 값을 가질 때까지 반복하여 근사화\n",
        "- 핵심 로직: 비용함수를 최소화하는 방향성을 가지고 회귀 계수의 업데이트 값을 구한 뒤, 이 업데이트 값을 회귀 계수에 반복적으로 적용\n",
        "  - 동일한 방식으로 L2 규제를 반영하여 실제 R행렬의 값과 예측 값의 차이를 최소화 하는 방향성으로 업데이트 수행 -> SGD 기반의 행렬분해 방식"
      ],
      "metadata": {
        "id": "bHnlPP27VBDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## SGD를 이용한 행렬 분해를 수행하는 예제\n",
        "import numpy as np\n",
        "\n",
        "# 원본 행렬 R 생성, 분해 행렬 P와 Q 초기화, 잠재 요인 차원 K는 3으로 설정.\n",
        "R = np.array([[4, np.nan, np.nan, 2, np.nan],\n",
        "             [np.nan, 5, np.nan, 3, 1],\n",
        "             [np.nan, np.nan, 3, 4, 4],\n",
        "             [5, 2, 1, 2, np.nan]])\n",
        "num_users, num_items = R.shape\n",
        "K=3\n",
        "\n",
        "# P와 Q 행렬의 크기를 지정하고 정규 분포를 가진 임의의 값으로 입력합니다.\n",
        "np.random.seed(1)\n",
        "P = np.random.normal(scale=1./K, size=(num_users, K))\n",
        "Q = np.random.normal(scale=1./K, size=(num_items, K))"
      ],
      "metadata": {
        "id": "RwA_OMLnVGqR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def get_rmse(R,P,Q,non_zeros):\n",
        "  error=0\n",
        "  # 두 개의 분해된 행렬 P와 Q.T의 내적으로 예측 R 행렬 생성\n",
        "  full_pred_metrix = np.dot(P,Q.T)\n",
        "\n",
        "  # 실제 R 행렬에서 널이 아닌 값의 위치 인덱스를 추출해 실제 R 행렬과 예측 행렬의 RMSE 추출\n",
        "  x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
        "  y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
        "  R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
        "  full_pred_matrix_non_zeros = full_pred_metrix[x_non_zero_ind, y_non_zero_ind]\n",
        "  mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
        "  rmse = np.sqrt(mse)\n",
        "\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "0Z7KvwzwVGuI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# R > 0인 행 위치, 열 위치, 값을 non_zeros 리스트에 저장.\n",
        "non_zeros = [(i,j,R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j]>0]\n",
        "\n",
        "steps=1000\n",
        "learning_rate=0.01\n",
        "r_lambda=0.01\n",
        "\n",
        "# SGD 기법으로 P와 Q 매트릭스를 계속 업데이트.\n",
        "for step in range(steps):\n",
        "  for i,j,r in non_zeros:\n",
        "    # 실제 값과 예측 값의 차이인 오류 값 구함\n",
        "    eij = r- np.dot(P[i, :], Q[j,:].T)\n",
        "    # Regularization을 반영한 SGD 업데이트 공식 적용\n",
        "    P[i,:] = P[i,:] + learning_rate*(eij * Q[j,:]- r_lambda*P[i,:])\n",
        "    Q[j,:] = Q[j,:] + learning_rate*(eij * P[i,:]- r_lambda*Q[j,:])\n",
        "\n",
        "  rmse = get_rmse(R,P,Q, non_zeros)\n",
        "  if (step %50) ==0:\n",
        "    print(\"### iteration step:\", step, \"rmse:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnKwm2M3VGyC",
        "outputId": "5340666f-6129-40fb-d37e-c6d725bd12ff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### iteration step: 0 rmse: 0.01670241003053959\n",
            "### iteration step: 50 rmse: 0.01665481399031652\n",
            "### iteration step: 100 rmse: 0.016607217134581766\n",
            "### iteration step: 150 rmse: 0.016559673722356366\n",
            "### iteration step: 200 rmse: 0.01651226578485758\n",
            "### iteration step: 250 rmse: 0.016465082173985138\n",
            "### iteration step: 300 rmse: 0.01641820796459579\n",
            "### iteration step: 350 rmse: 0.016371719574520292\n",
            "### iteration step: 400 rmse: 0.01632568298622087\n",
            "### iteration step: 450 rmse: 0.016280153596734587\n",
            "### iteration step: 500 rmse: 0.01623517687150329\n",
            "### iteration step: 550 rmse: 0.01619078934681494\n",
            "### iteration step: 600 rmse: 0.016147019735289377\n",
            "### iteration step: 650 rmse: 0.016103890007339142\n",
            "### iteration step: 700 rmse: 0.01606141638799138\n",
            "### iteration step: 750 rmse: 0.016019610245054067\n",
            "### iteration step: 800 rmse: 0.015978478864148105\n",
            "### iteration step: 850 rmse: 0.015938026116067937\n",
            "### iteration step: 900 rmse: 0.015898253026469866\n",
            "### iteration step: 950 rmse: 0.015859158259395788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_matrix = np.dot(P,Q.T)\n",
        "print(\"예측 행렬:\\n\", np.round(pred_matrix, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9JkAJaXVG1s",
        "outputId": "dcc915a6-5488-4400-b990-bc29ecd48ab2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 행렬:\n",
            " [[3.991 1.079 1.298 2.001 1.707]\n",
            " [6.301 4.978 0.868 2.982 1.003]\n",
            " [6.637 0.896 2.987 3.978 3.986]\n",
            " [4.969 2.005 1.007 2.014 1.281]]\n"
          ]
        }
      ]
    }
  ]
}